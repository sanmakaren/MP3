names(mtcars) %>%
str_c(collapse = " + ")
# Chunk 12
model_2 %>%
broom::tidy(conf.int = TRUE)
# Chunk 13
fitted_points_2 <- model_2 %>%
broom::augment()
fitted_points_2
# Chunk 14
model_2 %>%
broom::glance()
# Chunk 15
predicted_points_2 <- model_2 %>%
broom::augment(newdata = mtcars_test)
predicted_points_2
# Chunk 16
predicted_points_1 %>%
mutate(.resid = mpg - .fitted,
residsq = .resid^2) %>%
summarise(MSE = mean(residsq)) %>%
mutate(RMSE = sqrt(MSE))
# Chunk 17
predicted_points_2 %>%
mutate(.resid = mpg - .fitted,
residsq = .resid^2) %>%
summarise(MSE = mean(residsq)) %>%
mutate(RMSE = sqrt(MSE))
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
glimpse(sample_submission)
training$project_grade_category <- as.factor(training$project_grade_category)
training$project_grade_category <- relevel(training$project_grade_category, "Grades PreK-2")
test$project_grade_category <- as.factor(test$project_grade_category)
test$project_grade_category <- relevel(test$project_grade_category, "Grades PreK-2")
model_1 <- glm(project_is_approved~1, data= training)
fitted_points_model_1 <- model_1 %>%
broom::augment()
fitted_points_model_1 <- fitted_points_model_1 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
roc_auc(fitted_points_model_1, as.factor(project_is_approved), fitted_prob)
predict_model_1 <- model_1 %>%
broom::augment(newdata = test)
submission <- test %>%
mutate(
fitted_prob = 1/(1 + exp(-predict_model_1$.fitted)),
project_is_approved = (if_else(fitted_prob > 0.5, 1, 0) )
) %>%
select(id, project_is_approved)
write_csv(submission, path = "data/submission_model_1.csv")
autoplot(roc_curve(fitted_points_model_1, as.factor(project_is_approved), fitted_prob ))
hist(training$teacher_number_of_previously_posted_projects)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training)
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
fitted_points_model_1$teacher_number_of_previously_posted_projects <- training$teacher_number_of_previously_posted_projects
ggplot(data = fitted_points_model_2, aes(x=teacher_number_of_previously_posted_projects, y=project_is_approved)) +
geom_jitter(height=0.01) +
geom_line(data = fitted_points_model_1, mapping = aes(y = fitted_prob), col = "blue", size = 1) + #plot model_1 probabilities
geom_line(data = fitted_points_model_2, mapping = aes(y = fitted_prob), col = "red", size = 1) + #plot model_2 probabilities
labs(x = "number of perviously posted projects", y = "project is approved")
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
predict_model_2 <- model_2 %>%
broom::augment(newdata = test) %>%
mutate(fitted_prob = 1/(1 + exp(.fitted)))
ggplot(data=predict_model_2, aes(predict_model_2$fitted_prob)) +
geom_histogram() +
labs(x = "fitted probability", title = "model_2 on test data")
submission2 <- test %>%
mutate(project_is_approved = (if_else(predict_model_2$fitted_prob > 0.5, 1, 0) )) %>%
select(id, project_is_approved)
write_csv(submission2, path = "data/submission_model_2.csv")
autoplot(roc_curve(fitted_points_model_2, as.factor(project_is_approved), fitted_prob ))
model_3 <- glm(project_is_approved ~ project_grade_category, data= training)
fitted_points_model_3 <- model_3 %>%
broom::augment()
fitted_points_model_3 <- fitted_points_model_3 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
fitted_points_model_1$project_grade_category <- training$project_grade_category
# for some reason this doesn't work the same as above
ggplot(data = fitted_points_model_3, aes(x=project_grade_category, y=fitted_prob)) +
geom_boxplot() +
geom_line(
data = fitted_points_model_1, mapping = aes(y = fitted_prob, x =  project_grade_category, group = 1 ),
col = "blue", size = 1) +
labs(x = "grade level", y = "probability project approved")
roc_auc(fitted_points_model_3, as.factor(project_is_approved), fitted_prob)
predict_model_3 <- model_3 %>%
broom::augment(newdata = test) %>%
mutate(fitted_prob = 1/(1 + exp(.fitted)))
#does hisotogram need to show grade levels?
ggplot(data=predict_model_3, aes(fitted_prob)) +
geom_histogram() +
labs(x = "fitted probability", title = "model_3 on test data")
submission3 <- test %>%
mutate(project_is_approved = (if_else(predict_model_3$fitted_prob > 0.5, 1, 0) )) %>%
select(id, project_is_approved)
write_csv(submission3, path = "data/submission_model_3.csv")
autoplot(roc_curve(fitted_points_model_3, as.factor(project_is_approved), fitted_prob ))
model_4 <- glm(project_is_approved ~ project_grade_category + teacher_number_of_previously_posted_projects, data= training)
fitted_points_model_4 <- model_4 %>%
broom::augment()
fitted_points_model_4 <- fitted_points_model_4 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
autoplot(roc_curve(fitted_points_model_4, as.factor(project_is_approved), fitted_prob ))
roc_auc(fitted_points_model_4, as.factor(project_is_approved), fitted_prob)
View(submission)
View(submission2)
ithmic loss function indicative of better
# predictions or worse predictions?
library(tidyverse)
# Pre-process iris dataset
iris <- iris %>%
# Convert to tibble data frame:
as_tibble() %>%
# Add identification variable to uniquely identify each row:
rownames_to_column(var="ID")
library(rpart)
model_formula <- as.formula(Species ~ Sepal.Length + Sepal.Width)
tree_parameters <- rpart.control(maxdepth = 3)
model_CART <- rpart(model_formula, data = iris, control = tree_parameters)
plot(model_CART, margin=0.25)
text(model_CART, use.n = TRUE)
title("Predicting iris species using sepal length & width")
box()
# Pre-process iris dataset
iris <- iris %>%
# Convert to tibble data frame:
as_tibble() %>%
# Add identification variable to uniquely identify each row:
rownames_to_column(var="ID")
library(rpart)
model_formula <- as.formula(Species ~ Sepal.Length + Sepal.Width)
tree_parameters <- rpart.control(maxdepth = 3)
model_CART <- rpart(model_formula, data = iris, control = tree_parameters)
text(model_CART, use.n = TRUE)
plot(model_CART, margin=0.25)
text(model_CART, use.n = TRUE)
title("Predicting iris species using sepal length & width")
box()
ggplot(data = fitted_points_model_3, aes(x=project_grade_category, y=fitted_prob)) +
geom_boxplot() +
geom_boxplot(
data = fitted_points_model_1, mapping = aes(y = fitted_prob, x =  project_grade_category ),
col = "blue", size = 1) +
labs(x = "grade level", y = "probability project approved")
ggplot(data = fitted_points_model_3, aes(x=project_grade_category, y=fitted_prob)) +
geom_boxplot() +
geom_line(
data = fitted_points_model_1, mapping = aes(y = fitted_prob, x =  project_grade_category ),
col = "blue", size = 1) +
labs(x = "grade level", y = "probability project approved")
ggplot(data = fitted_points_model_3, aes(x=project_grade_category, y=fitted_prob)) +
geom_boxplot() +
geom_line(
data = fitted_points_model_1, mapping = aes(y = fitted_prob, x =  project_grade_category, group=1 ),
col = "blue", size = 1) +
labs(x = "grade level", y = "probability project approved")
submission2 <- test %>%
mutate(project_is_approved = fitted_prob) %>%
select(id, project_is_approved)
# Chunk 1: setup
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
# Chunk 2
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
# Chunk 4
glimpse(sample_submission)
# Chunk 5
training$project_grade_category <- as.factor(training$project_grade_category)
training$project_grade_category <- relevel(training$project_grade_category, "Grades PreK-2")
test$project_grade_category <- as.factor(test$project_grade_category)
test$project_grade_category <- relevel(test$project_grade_category, "Grades PreK-2")
# Chunk 6
model_1 <- glm(project_is_approved~1, data= training)
# Chunk 7
fitted_points_model_1 <- model_1 %>%
broom::augment()
# Chunk 8
fitted_points_model_1 <- fitted_points_model_1 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
roc_auc(fitted_points_model_1, as.factor(project_is_approved), fitted_prob)
# Chunk 9
predict_model_1 <- model_1 %>%
broom::augment(newdata = test)
# Chunk 10
submission <- test %>%
mutate(
fitted_prob = 1/(1 + exp(-predict_model_1$.fitted)),
project_is_approved = (if_else(fitted_prob > 0.5, 1, 0) )
) %>%
select(id, project_is_approved)
write_csv(submission, path = "data/submission_model_1.csv")
# Chunk 11
autoplot(roc_curve(fitted_points_model_1, as.factor(project_is_approved), fitted_prob ))
# Chunk 12
hist(training$teacher_number_of_previously_posted_projects)
# Chunk 13
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training)
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
fitted_points_model_1$teacher_number_of_previously_posted_projects <- training$teacher_number_of_previously_posted_projects
ggplot(data = fitted_points_model_2, aes(x=teacher_number_of_previously_posted_projects, y=project_is_approved)) +
geom_jitter(height=0.01) +
geom_line(data = fitted_points_model_1, mapping = aes(y = fitted_prob), col = "blue", size = 1) + #plot model_1 probabilities
geom_line(data = fitted_points_model_2, mapping = aes(y = fitted_prob), col = "red", size = 1) + #plot model_2 probabilities
labs(x = "number of perviously posted projects", y = "project is approved")
# Chunk 14
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
# Chunk 15
predict_model_2 <- model_2 %>%
broom::augment(newdata = test) %>%
mutate(fitted_prob = 1/(1 + exp(.fitted)))
ggplot(data=predict_model_2, aes(predict_model_2$fitted_prob)) +
geom_histogram() +
labs(x = "fitted probability", title = "model_2 on test data")
# Chunk 16
submission2 <- test %>%
mutate(project_is_approved = (if_else(predict_model_2$fitted_prob > 0.5, 1, 0) )) %>%
select(id, project_is_approved)
submission2 <- test %>%
mutate(project_is_approved = fitted_prob) %>%
select(id, project_is_approved)
write_csv(submission2, path = "data/submission_model_2.csv")
# Chunk 17
autoplot(roc_curve(fitted_points_model_2, as.factor(project_is_approved), fitted_prob ))
# Chunk 18
model_3 <- glm(project_is_approved ~ project_grade_category, data= training)
fitted_points_model_3 <- model_3 %>%
broom::augment()
fitted_points_model_3 <- fitted_points_model_3 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
fitted_points_model_1$project_grade_category <- training$project_grade_category
# for some reason this doesn't work the same as above
ggplot(data = fitted_points_model_3, aes(x=project_grade_category, y=fitted_prob)) +
geom_boxplot() +
geom_line(
data = fitted_points_model_1, mapping = aes(y = fitted_prob, x =  project_grade_category, group=1 ),
col = "blue", size = 1) +
labs(x = "grade level", y = "probability project approved")
# Chunk 19
roc_auc(fitted_points_model_3, as.factor(project_is_approved), fitted_prob)
# Chunk 20
predict_model_3 <- model_3 %>%
broom::augment(newdata = test) %>%
mutate(fitted_prob = 1/(1 + exp(.fitted)))
#does hisotogram need to show grade levels?
ggplot(data=predict_model_3, aes(fitted_prob)) +
geom_histogram() +
labs(x = "fitted probability", title = "model_3 on test data")
# Chunk 21
submission3 <- test %>%
mutate(project_is_approved = (if_else(predict_model_3$fitted_prob > 0.5, 1, 0) )) %>%
select(id, project_is_approved)
write_csv(submission3, path = "data/submission_model_3.csv")
# Chunk 22
autoplot(roc_curve(fitted_points_model_3, as.factor(project_is_approved), fitted_prob ))
# Chunk 23
model_4 <- glm(project_is_approved ~ project_grade_category + teacher_number_of_previously_posted_projects, data= training)
fitted_points_model_4 <- model_4 %>%
broom::augment()
fitted_points_model_4 <- fitted_points_model_4 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted)),
binary_estimate = (if_else(fitted_prob > 0.5, 1, 0) )
)
autoplot(roc_curve(fitted_points_model_4, as.factor(project_is_approved), fitted_prob ))
roc_auc(fitted_points_model_4, as.factor(project_is_approved), fitted_prob)
model_4 <- glm(project_is_approved ~ project_grade_category + teacher_number_of_previously_posted_projects, data= training)
fitted_points_model_4 <- model_4 %>%
broom::augment()
model_4 <- glm(project_is_approved ~ project_grade_category + teacher_number_of_previously_posted_projects, data= training)
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
submission2 <- test %>%
mutate(project_is_approved = fitted_prob) %>%
select(id, project_is_approved)
write_csv(submission2, path = "data/submission_model_2.csv")
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
training$project_is_approved <- factor(training$project_is_approved,levels=c("0","1"))
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
install.packages("yardstick")
libaray(yardstick)
library(yardstick)
sessionInfo(yardstick)
sessionInfo()
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted))
)
# Load all your packages here:
library(tidyverse)
library(yardstick)
# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 16/2, fig.height = 9/2
)
# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
setwd("documents/github/mp3")
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
training$project_grade_category <- as.factor(training$project_grade_category)
training$project_grade_category <- relevel(training$project_grade_category, "Grades PreK-2")
test$project_grade_category <- as.factor(test$project_grade_category)
test$project_grade_category <- relevel(test$project_grade_category, "Grades PreK-2")
model_1 <- glm(project_is_approved~1, data= training, family = binomial())
fitted_points_model_1 <- model_1 %>%
broom::augment()
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(-.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = exp(.fitted)/(1 + exp(.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1 -  1/(1 + exp(-.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
model_2 <- glm(project_is_approved ~ teacher_number_of_previously_posted_projects, data= training, family = binomial())
fitted_points_model_2 <- model_2 %>%
broom::augment()
fitted_points_model_2 <- fitted_points_model_2 %>%
mutate(
fitted_prob = 1/(1 + exp(.fitted))
)
roc_auc(fitted_points_model_2, as.factor(project_is_approved), fitted_prob)
